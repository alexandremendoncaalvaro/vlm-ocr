# Hugging Face access token for authenticated downloads
HF_TOKEN=hf_your_token_here

# Where to store downloaded GGUF weights
MODEL_DIR=models

# Default model filenames (override if you prefer other quantizations)
MODEL_QUANT=llava-v1.6-mistral-7b.Q4_K_M.gguf
MMPROJ_FILE=mmproj-model-f16.gguf

# Source URLs (override to swap models)
MODEL_URL=https://huggingface.co/mradermacher/llava-v1.6-mistral-7b-GGUF/resolve/main/llava-v1.6-mistral-7b.Q4_K_M.gguf
MMPROJ_URL=https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b/resolve/main/mmproj-model-f16.gguf
